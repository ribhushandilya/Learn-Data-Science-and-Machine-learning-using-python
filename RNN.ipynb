{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01803f89-1de2-408b-b2fd-f4131bb9d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d49e2d-6e31-4706-9c8f-b623a34fb88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = [\n",
    "    \"sender\", \"youremail@example.com\",\n",
    "    \"recipient\", \"recipient@example.com\",\n",
    "    \"subject\", \"Regarding Project Update\",\n",
    "    \"body\", \n",
    "    'Dear' ,'I', 'hope', 'this', 'email', 'finds', 'you', 'well','.', 'I', 'wanted', 'to', 'update', 'you' ,'on', 'the', 'current', 'status', 'of', 'the', 'project','.','If', 'you', 'have', 'any', 'specific', 'requirements', 'or', 'need', 'further', 'details',',', 'please', 'let' ,'me', 'know','.','Best', 'regards','Name'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8e1d09-1c10-4289-bd63-7527ce0f1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token = '<nothing>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2f5551-3123-4cf1-b2db-0e15abaf7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cff2a66-aab2-4b71-a37d-7b7831b91e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('sender', 1),\n",
       "             ('youremail', 1),\n",
       "             ('example', 2),\n",
       "             ('com', 2),\n",
       "             ('recipient', 2),\n",
       "             ('subject', 1),\n",
       "             ('regarding', 1),\n",
       "             ('project', 2),\n",
       "             ('update', 2),\n",
       "             ('body', 1),\n",
       "             ('dear', 1),\n",
       "             ('i', 2),\n",
       "             ('hope', 1),\n",
       "             ('this', 1),\n",
       "             ('email', 1),\n",
       "             ('finds', 1),\n",
       "             ('you', 3),\n",
       "             ('well', 1),\n",
       "             ('wanted', 1),\n",
       "             ('to', 1),\n",
       "             ('on', 1),\n",
       "             ('the', 2),\n",
       "             ('current', 1),\n",
       "             ('status', 1),\n",
       "             ('of', 1),\n",
       "             ('if', 1),\n",
       "             ('have', 1),\n",
       "             ('any', 1),\n",
       "             ('specific', 1),\n",
       "             ('requirements', 1),\n",
       "             ('or', 1),\n",
       "             ('need', 1),\n",
       "             ('further', 1),\n",
       "             ('details', 1),\n",
       "             ('please', 1),\n",
       "             ('let', 1),\n",
       "             ('me', 1),\n",
       "             ('know', 1),\n",
       "             ('best', 1),\n",
       "             ('regards', 1),\n",
       "             ('name', 1)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5d7e89-34a9-433b-8bb9-75cf7cc724b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<nothing>': 1,\n",
       " 'you': 2,\n",
       " 'example': 3,\n",
       " 'com': 4,\n",
       " 'recipient': 5,\n",
       " 'project': 6,\n",
       " 'update': 7,\n",
       " 'i': 8,\n",
       " 'the': 9,\n",
       " 'sender': 10,\n",
       " 'youremail': 11,\n",
       " 'subject': 12,\n",
       " 'regarding': 13,\n",
       " 'body': 14,\n",
       " 'dear': 15,\n",
       " 'hope': 16,\n",
       " 'this': 17,\n",
       " 'email': 18,\n",
       " 'finds': 19,\n",
       " 'well': 20,\n",
       " 'wanted': 21,\n",
       " 'to': 22,\n",
       " 'on': 23,\n",
       " 'current': 24,\n",
       " 'status': 25,\n",
       " 'of': 26,\n",
       " 'if': 27,\n",
       " 'have': 28,\n",
       " 'any': 29,\n",
       " 'specific': 30,\n",
       " 'requirements': 31,\n",
       " 'or': 32,\n",
       " 'need': 33,\n",
       " 'further': 34,\n",
       " 'details': 35,\n",
       " 'please': 36,\n",
       " 'let': 37,\n",
       " 'me': 38,\n",
       " 'know': 39,\n",
       " 'best': 40,\n",
       " 'regards': 41,\n",
       " 'name': 42}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84368b7-7ebb-47a1-af32-5ad8789ba544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f841b3-28ec-409b-a53e-3760658d8d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10],\n",
       " [11, 3, 4],\n",
       " [5],\n",
       " [5, 3, 4],\n",
       " [12],\n",
       " [13, 6, 7],\n",
       " [14],\n",
       " [15],\n",
       " [8],\n",
       " [16],\n",
       " [17],\n",
       " [18],\n",
       " [19],\n",
       " [2],\n",
       " [20],\n",
       " [],\n",
       " [8],\n",
       " [21],\n",
       " [22],\n",
       " [7],\n",
       " [2],\n",
       " [23],\n",
       " [9],\n",
       " [24],\n",
       " [25],\n",
       " [26],\n",
       " [9],\n",
       " [6],\n",
       " [],\n",
       " [27],\n",
       " [2],\n",
       " [28],\n",
       " [29],\n",
       " [30],\n",
       " [31],\n",
       " [32],\n",
       " [33],\n",
       " [34],\n",
       " [35],\n",
       " [],\n",
       " [36],\n",
       " [37],\n",
       " [38],\n",
       " [39],\n",
       " [],\n",
       " [40],\n",
       " [41],\n",
       " [42]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = tokenizer.texts_to_sequences(email)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b8c2cd-ec94-490e-b558-a8893a5b7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc91c50-0f86-49c9-b39d-344ef8a34e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=pad_sequences(seq,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e279488-8e29-42cf-9a75-03017e900ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [11,  3,  4],\n",
       "       [ 5,  0,  0],\n",
       "       [ 5,  3,  4],\n",
       "       [12,  0,  0],\n",
       "       [13,  6,  7],\n",
       "       [14,  0,  0],\n",
       "       [15,  0,  0],\n",
       "       [ 8,  0,  0],\n",
       "       [16,  0,  0],\n",
       "       [17,  0,  0],\n",
       "       [18,  0,  0],\n",
       "       [19,  0,  0],\n",
       "       [ 2,  0,  0],\n",
       "       [20,  0,  0],\n",
       "       [ 0,  0,  0],\n",
       "       [ 8,  0,  0],\n",
       "       [21,  0,  0],\n",
       "       [22,  0,  0],\n",
       "       [ 7,  0,  0],\n",
       "       [ 2,  0,  0],\n",
       "       [23,  0,  0],\n",
       "       [ 9,  0,  0],\n",
       "       [24,  0,  0],\n",
       "       [25,  0,  0],\n",
       "       [26,  0,  0],\n",
       "       [ 9,  0,  0],\n",
       "       [ 6,  0,  0],\n",
       "       [ 0,  0,  0],\n",
       "       [27,  0,  0],\n",
       "       [ 2,  0,  0],\n",
       "       [28,  0,  0],\n",
       "       [29,  0,  0],\n",
       "       [30,  0,  0],\n",
       "       [31,  0,  0],\n",
       "       [32,  0,  0],\n",
       "       [33,  0,  0],\n",
       "       [34,  0,  0],\n",
       "       [35,  0,  0],\n",
       "       [ 0,  0,  0],\n",
       "       [36,  0,  0],\n",
       "       [37,  0,  0],\n",
       "       [38,  0,  0],\n",
       "       [39,  0,  0],\n",
       "       [ 0,  0,  0],\n",
       "       [40,  0,  0],\n",
       "       [41,  0,  0],\n",
       "       [42,  0,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06cda461-9e27-4c20-9b78-54ff73c7fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=pad_sequences(seq,padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67b80d2d-dc35-43d9-a6df-e8b699f6080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 10],\n",
       "       [11,  3,  4],\n",
       "       [ 0,  0,  5],\n",
       "       [ 5,  3,  4],\n",
       "       [ 0,  0, 12],\n",
       "       [13,  6,  7],\n",
       "       [ 0,  0, 14],\n",
       "       [ 0,  0, 15],\n",
       "       [ 0,  0,  8],\n",
       "       [ 0,  0, 16],\n",
       "       [ 0,  0, 17],\n",
       "       [ 0,  0, 18],\n",
       "       [ 0,  0, 19],\n",
       "       [ 0,  0,  2],\n",
       "       [ 0,  0, 20],\n",
       "       [ 0,  0,  0],\n",
       "       [ 0,  0,  8],\n",
       "       [ 0,  0, 21],\n",
       "       [ 0,  0, 22],\n",
       "       [ 0,  0,  7],\n",
       "       [ 0,  0,  2],\n",
       "       [ 0,  0, 23],\n",
       "       [ 0,  0,  9],\n",
       "       [ 0,  0, 24],\n",
       "       [ 0,  0, 25],\n",
       "       [ 0,  0, 26],\n",
       "       [ 0,  0,  9],\n",
       "       [ 0,  0,  6],\n",
       "       [ 0,  0,  0],\n",
       "       [ 0,  0, 27],\n",
       "       [ 0,  0,  2],\n",
       "       [ 0,  0, 28],\n",
       "       [ 0,  0, 29],\n",
       "       [ 0,  0, 30],\n",
       "       [ 0,  0, 31],\n",
       "       [ 0,  0, 32],\n",
       "       [ 0,  0, 33],\n",
       "       [ 0,  0, 34],\n",
       "       [ 0,  0, 35],\n",
       "       [ 0,  0,  0],\n",
       "       [ 0,  0, 36],\n",
       "       [ 0,  0, 37],\n",
       "       [ 0,  0, 38],\n",
       "       [ 0,  0, 39],\n",
       "       [ 0,  0,  0],\n",
       "       [ 0,  0, 40],\n",
       "       [ 0,  0, 41],\n",
       "       [ 0,  0, 42]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e211ac-f86d-47b1-a981-7630d6da5e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
